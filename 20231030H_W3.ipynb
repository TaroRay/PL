{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "GbJmTRaxuFpK"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import json\n",
        "\n",
        "num_pages = 30 #爬蟲資料筆數\n",
        "search_keyword = \"披薩\"  # 美食版搜尋關鍵字\n",
        "url = 'https://www.ptt.cc/bbs/Food/index.html' #連結到PTT美食版網址"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "session = requests.session()       #檢測是否連線 正確連線伺服器回應200\n",
        "payload = {\n",
        "    'from': '/bbs/Food/index.html',\n",
        "    'yes': 'yes'\n",
        "}\n",
        "session.post('https://www.ptt.cc/ask/over18', data=payload)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvINzLaEyZs7",
        "outputId": "26baa7f5-616c-4a08-8b16-2dd4a33f7169"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matching_titles = []\n",
        "\n",
        "for i in range(num_pages):\n",
        "    response = session.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # 解析內容\n",
        "    for article in soup.find_all(class_='r-ent'):\n",
        "        title = article.find(class_='title').text.strip()\n",
        "        if search_keyword in title:\n",
        "            matching_titles.append(title)\n",
        "    paging = soup.find(class_='btn-group-paging')\n",
        "    previous_page_link = paging.find_all('a')[1]['href']\n",
        "    url = 'https://www.ptt.cc' + previous_page_link"
      ],
      "metadata": {
        "id": "d4Z1oyaQypVT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 列印列表\n",
        "for title in matching_titles:\n",
        "    print(title)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9ixw4qvy8y6",
        "outputId": "6e4d101d-bf9e-4e35-831c-818681e88045"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[食記] 義大利Verona i Tigli北義披薩的頂峰\n",
            "[食記] 義大利Verona方盤披薩名店Sapore pizza\n",
            "[食記] 義大利Caserta世界第一披薩店Martucci\n",
            "[食記] 義大利Caiazzo披薩名店Pepe In Grani\n",
            "[食記] 荷蘭阿姆斯特丹 nNea Pizza拿坡里披薩店\n",
            "[食記] 好吃好拍pizzeria | 台北大安小紐約披薩\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 將結果存儲為CSV檔\n",
        "csv_filename = 'matching_titles.csv'\n",
        "with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "    csv_writer = csv.writer(csvfile)\n",
        "    csv_writer.writerow(['Title'])\n",
        "    for title in matching_titles:\n",
        "        csv_writer.writerow([title])\n",
        "\n",
        "# 將結果存儲為JSON檔\n",
        "json_filename = 'matching_titles.json'\n",
        "with open(json_filename, 'w', encoding='utf-8') as jsonfile:\n",
        "    json.dump(matching_titles, jsonfile, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f'Results saved as {csv_filename} and {json_filename}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qceLpxRx-NV",
        "outputId": "d8121122-7766-4df8-f3f3-72f1d7e3485c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved as matching_titles.csv and matching_titles.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "csv_filename = '/content/drive/My Drive/Colab Notebooks/matching_titles.csv'\n",
        "with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "    csv_writer = csv.writer(csvfile)\n",
        "    csv_writer.writerow(['Title'])\n",
        "    for title in matching_titles:\n",
        "        csv_writer.writerow([title])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZVzQobhvOAb",
        "outputId": "2325b3cd-8ee4-485c-9b2f-ca36fc38c8fb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json_filename = '/content/drive/My Drive/Colab Notebooks/matching_titles.json'\n",
        "with open(json_filename, 'w', encoding='utf-8') as jsonfile:\n",
        "    json.dump(matching_titles, jsonfile, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "id": "wI67M--hvXAt"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}